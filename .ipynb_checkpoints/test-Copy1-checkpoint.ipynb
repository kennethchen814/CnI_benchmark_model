{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from copy import deepcopy\n",
    "\n",
    "account_data = pd.read_csv(\"Jumbo_g.csv\")\n",
    "#print(account_data.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the portfolio: \n",
      " 1 C&I \n",
      " 2 CRE \n",
      " 3 All \n",
      "3\n",
      "\n",
      " Select the reversion method: \n",
      " 1 TTC transition matrix \n",
      " 2 Last PIT transition matrix \n",
      "2\n",
      "\n",
      " Select the macroeconomic forecast scenario: \n",
      " 1 Baseline \n",
      " 2 Adverse \n",
      " 3 Severely Adverse \n",
      "2\n",
      "\n",
      " Input the length of R&S period in quarters \n",
      "13\n",
      "\n",
      " Select the LGD approach: \n",
      " 1 Fixed LGD from user input \n",
      " 2 Frye-Jacobs LGD \n",
      "2\n",
      "\n",
      " Select the Prepayment Rate option: \n",
      " 1 Fixed rate from user input \n",
      " 2 Rate provided in the data \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "portfolio  = int(input(\"Select the portfolio: \\n 1 C&I \\n 2 CRE \\n 3 All \\n\"))\n",
    "reversion  = int(input(\"\\n Select the reversion method: \\n 1 TTC transition matrix \\n 2 Last PIT transition matrix \\n\"))\n",
    "scenario   = int(input(\"\\n Select the macroeconomic forecast scenario: \\n 1 Baseline \\n 2 Adverse \\n 3 Severely Adverse \\n\"))\n",
    "rs_len     = int(input(\"\\n Input the length of R&S period in quarters \\n\"))\n",
    "LGD_option = int(input(\"\\n Select the LGD approach: \\n 1 Fixed LGD from user input \\n 2 Frye-Jacobs LGD \\n\"))\n",
    "if LGD_option == 1:\n",
    "    LGD_val = float(input(\"\\n Input the value of fixed LGD: \"))\n",
    "    \n",
    "PP_option = int(input(\"\\n Select the Prepayment Rate option: \\n 1 Fixed rate from user input \\n 2 Rate provided in the data \\n\"))\n",
    "if PP_option == 1:\n",
    "    PP_val = float(input(\"\\n Input the value of fixed Prepayment Rate: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import segment level TTC transition matrix and historical default rate\n",
    "segment = [\"Fin_US\",\"Oil_US\",\"Cyc_US_2clst\",\"NCy_US\",\"Fin_NUS\",\"Oil_NUS\",\"Cyc_NUS\",\"NCy_NUS\",\"Sov\"]\n",
    "TMlist = {}\n",
    "DRlist = {}\n",
    "\n",
    "for s in segment:\n",
    "    TMlist[s] = pd.read_excel(\"TM_AllSeg.xls\", sheet_name = s)\n",
    "    DRlist[s] = pd.read_csv(\"DR_\"+s+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normallize the rating migration matrix so that each row adds up to 1\n",
    "def rel_mat():\n",
    "    rel_mat_t_list = {}\n",
    "    for s in range(0, len(segment)):\n",
    "        rel_mat_t = TMlist[segment[s]].drop([\"rating_alph\"], axis=1)\n",
    "        for j in range(0, rel_mat_t.shape[1]):\n",
    "            rel_mat_t.iloc[:,j] = rel_mat_t.iloc[:,j]/rel_mat_t.sum(axis=1)\n",
    "        rel_mat_t_list[s] = rel_mat_t\n",
    "    return rel_mat_t_list\n",
    "\n",
    "x = rel_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the number of ratings and number of forecast period based on TTC transition matrix \n",
    "# and the maximum remaining maturity of the portfolio\n",
    "states = (x[1].shape[1])\n",
    "horizon = max(20, math.ceil(account_data[\"RemMat\"].max() + 0.0001))\n",
    "\n",
    "# Create a matrix to store the marginal PD in the forecast periods\n",
    "mpd_mat_AllSeg = np.zeros((states * len(segment), horizon), dtype = float)\n",
    "for s in range(0, len(segment)):\n",
    "    pd_mat = np.zeros((states, horizon), dtype = float) #Cumulative PD#\n",
    "    mpd_mat = np.zeros((states, horizon), dtype = float) #Marginal PD Matrix\n",
    "    mat = rel_mat()[s]\n",
    "    pd_mat[:, 0] = mat.iloc[:, states-1]\n",
    "    mpd_mat[:,0] = pd_mat[:,0]\n",
    "\n",
    "    #-- Creating PD Matrix, PD IN HORIZONS (pd_mat) --#\n",
    "    pom_mat = mat\n",
    "    for i in range(1, horizon):\n",
    "        pom_mat = np.dot(pom_mat, mat)\n",
    "        pd_mat[:, i] = pom_mat[:,states-1]\n",
    "        mpd_mat[:,i] = pd_mat[:, i] - pd_mat[:, i - 1]\n",
    "    row1 = s*states\n",
    "    row2 = (s+1)*states\n",
    "    mpd_mat_AllSeg[row1:row2, :] = mpd_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import historical macroeconomic variables and scenario forecast\n",
    "macro_hist = pd.read_csv(\"Supervisory historical Domestic.csv\")\n",
    "macro_base = pd.read_csv(\"base.csv\")\n",
    "macro_adv = pd.read_csv(\"adv.csv\")\n",
    "macro_sa = pd.read_csv(\"sa.csv\")\n",
    "\n",
    "if scenario == 1:\n",
    "    macro_scenario = macro_hist.append(macro_base)\n",
    "elif scenario == 2:\n",
    "    macro_scenario = macro_hist.append(macro_adv)\n",
    "else:\n",
    "    macro_scenario = macro_hist.append(macro_sa)\n",
    "\n",
    "# Keep the MEVs used in regression and generate lags up to 2 quarters\n",
    "def MacroTrans(macro):\n",
    "    period_len = macro.shape[0]\n",
    "    macro[\"period\"] = pd.date_range('1976-03-01', periods=period_len, freq='Q')\n",
    "    \n",
    "    macro = macro[macro.period > '1989-12-31']\n",
    "\n",
    "    macro = macro[[\"period\", \"Real GDP growth\", \"Unemployment rate\", \"10-year Treasury yield\", \"BBB corporate yield\", \n",
    "                   \"Dow Jones Total Stock Market Index (Level)\", \"Market Volatility Index (Level)\", \"WTI Price\",\n",
    "                   \"Euro area real GDP growth\"]]\n",
    "    macro.columns = [\"period\", \"usgdp\", \"ur\", \"tenyr_yield\", \"bbb_yield\", \"djix\", \"vix\", \"wti\", \"eugdp\"]\n",
    "    macro[\"spread\"] = macro[\"bbb_yield\"] - macro[\"tenyr_yield\"]\n",
    "    macro[\"djix_lag4\"] = macro[\"djix\"].shift(periods=4)\n",
    "    macro[\"djgr\"] = macro[\"djix\"]/macro[\"djix_lag4\"] - 1\n",
    "    macro[\"vix_lag4\"] = macro[\"vix\"].shift(periods=4)\n",
    "    macro[\"vixgr\"] = macro[\"vix\"]/macro[\"vix_lag4\"] - 1\n",
    "    macro[\"wti_lag4\"] = macro[\"wti\"].shift(periods=4)\n",
    "    macro[\"wtigr\"] = macro[\"wti\"]/macro[\"wti_lag4\"] - 1\n",
    "    \n",
    "\n",
    "    macro = macro[[\"period\", \"usgdp\", \"ur\", \"spread\", \"djgr\", \"vixgr\", \"wtigr\", \"eugdp\"]]\n",
    "    colname = macro.columns.values\n",
    "    for i in range(1,len(colname)):\n",
    "        macro[colname[i]+\"_lag1\"] = macro[colname[i]].shift(periods=1)\n",
    "        macro[colname[i]+\"_lag2\"] = macro[colname[i]].shift(periods=2)\n",
    "        macro.rename(columns={colname[i]: colname[i]+\"_lag0\"}, inplace=True)\n",
    "\n",
    "    macro.dropna(inplace=True)\n",
    "    return macro\n",
    "\n",
    "macro_hist_final = MacroTrans(macro_hist)\n",
    "macro_scenario_final = MacroTrans(macro_scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011133\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030832\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006753\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.044815\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022509\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029479\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.038066\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566189\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.038066\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651920\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "# Generate segment level default rate data\n",
    "segment2 = [\"Fin_US\",\"Oil_US\",\"Fin_NUS\",\"Oil_NUS\",\"Cyc_NUS\",\"NCy_NUS\",\"Cyc_US1\",\"Cyc_US2\",\"NCy_US1\",\"NCy_US2\",\"Sov\"]\n",
    "PDlist = {}\n",
    "for s in range(0, len(segment2)-5):\n",
    "    PDlist[segment2[s]] = DRlist[segment2[s]][[\"period\",\"PD1\"]].copy()\n",
    "\n",
    "# For two segments (US Cyclical and US Non-Cyclical), the default rate is further separated by rating groups\n",
    "PDlist[\"Cyc_US1\"] = DRlist[\"Cyc_US_2clst\"][[\"period\",\"PD2\"]].copy()\n",
    "PDlist[\"Cyc_US2\"] = DRlist[\"Cyc_US_2clst\"][[\"period\",\"PD3\"]].copy().copy()\n",
    "PDlist[\"NCy_US1\"] = DRlist[\"Cyc_US_2clst\"][[\"period\",\"PD2\"]].copy()\n",
    "PDlist[\"NCy_US2\"] = DRlist[\"NCy_US\"][[\"period\",\"PD4\"]].copy()\n",
    "PDlist[\"Sov\"] = DRlist[\"Sov\"][[\"period\",\"PD1\"]].copy()\n",
    "\n",
    "# Define MEVs used in each of the segments\n",
    "MEVlist = {}\n",
    "MEVlist[\"Fin_US\"] = [\"usgdp_lag0\", \"spread_lag1\"]\n",
    "MEVlist[\"Oil_US\"] = [\"vixgr_lag0\", \"wtigr_lag1\"]\n",
    "MEVlist[\"Oil_NUS\"] = [\"spread_lag0\", \"wtigr_lag2\"]\n",
    "MEVlist[\"Fin_NUS\"] = [\"ur_lag2\", \"spread_lag0\"]\n",
    "MEVlist[\"Cyc_NUS\"] = [\"spread_lag1\", \"djgr_lag0\"]\n",
    "MEVlist[\"NCy_NUS\"] = [\"djgr_lag2\", \"vixgr_lag0\"]\n",
    "MEVlist[\"Cyc_US1\"] = [\"usgdp_lag0\", \"djgr_lag0\"]\n",
    "MEVlist[\"Cyc_US2\"] = [\"usgdp_lag0\", \"spread_lag1\"]\n",
    "MEVlist[\"NCy_US1\"] = [\"usgdp_lag0\", \"djgr_lag0\"]\n",
    "MEVlist[\"NCy_US2\"] = [\"spread_lag2\", \"vixgr_lag0\"]\n",
    "\n",
    "# Run the regression model of historical default rate on MEVs and generate PD forecast to derive the shift factor\n",
    "Shiftlist = {}\n",
    "for s in range(0, len(segment2)-1):\n",
    "    # Prepare data for regression by merging the MEVs with historical default rate\n",
    "    PDlist[segment2[s]][\"period\"] = pd.date_range(PDlist[segment2[s]][\"period\"][0], periods=PDlist[segment2[s]].shape[0], freq='Q')\n",
    "    PDlist[segment2[s]].rename(columns={PDlist[segment2[s]].columns.values[1]:\"PD\"}, inplace=True)\n",
    "    RegData_final = PDlist[segment2[s]].merge(macro_hist_final, left_on=\"period\", right_on=\"period\")\n",
    "    RegData_final = RegData_final.dropna()\n",
    "    \n",
    "    # Run fractional logit regression\n",
    "    import statsmodels.api as sm\n",
    "    Y = RegData_final[\"PD\"]\n",
    "    X = sm.add_constant(RegData_final[MEVlist[segment2[s]]])\n",
    "    mod = sm.Logit(Y,X)\n",
    "    res = mod.fit()\n",
    "    #print(res.summary())\n",
    "    \n",
    "    # Generate PD forecast\n",
    "    predict = res.predict(sm.add_constant(macro_scenario_final[MEVlist[segment2[s]]]))\n",
    "    PD_Forecast_Qtrs = pd.concat([macro_scenario_final[\"period\"].loc[0:12], predict.loc[0:12]], axis=1)\n",
    "    PD_Forecast_Qtrs.columns = [\"period\", \"PD_fcst\"]\n",
    "    \n",
    "    # Calculate the shift factor\n",
    "    PD_hist_mean = RegData_final.PD.mean()\n",
    "    \n",
    "    from scipy.stats import norm\n",
    "    PD_Shift = deepcopy(PD_Forecast_Qtrs)\n",
    "    PD_Shift[\"PD_mean\"] = PD_hist_mean\n",
    "    PD_Shift[\"fcst\"] = PD_Shift[\"PD_mean\"].apply(norm.ppf) - PD_Shift[\"PD_fcst\"].apply(norm.ppf)\n",
    "    \n",
    "    Shiftlist[segment2[s]] = PD_Shift\n",
    "\n",
    "# Temporarily use the shift factor of the NCy_US2 segment for the Sovereign segment\n",
    "# Later need to apply the P-T LDPD method for the Sovereign segment\n",
    "Shiftlist[\"Sov\"] = PD_Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Obtain PIT Transition Matrices from TTC Matrices by Applying Shift Factors to the Adjusted TTC Matrix--#\n",
    "PIT_mat_fcst = {}\n",
    "PIT_mat_fcst_AllSeg = {}\n",
    "\n",
    "for h in range(0, len(PD_Forecast_Qtrs[\"period\"])):\n",
    "    PIT_mat_fcst_AllSeg[h] = np.zeros((states * len(segment), states), dtype = float)\n",
    "\n",
    "# Define the function to convert TTC matrices to PIT matrices\n",
    "def PIT_matrix(TTC_mat, shift_table1, shift_table2, cut, quarter):\n",
    "    PIT_mat = deepcopy(TTC_mat)\n",
    "    for i in range(0, states-1):\n",
    "        shift_table = deepcopy(shift_table1)\n",
    "        if i>cut:\n",
    "            shift_table = deepcopy(shift_table2)\n",
    "        #Last Column of Transition Matrix (i.e. PD) Decreased by the Shift Factor#\n",
    "        PIT_mat.iloc[[i], [states-1]] = norm.cdf(norm.ppf(TTC_mat.iloc[[i],[states-1]]) - shift_table[\"fcst\"][quarter])\n",
    "\n",
    "        #Adjusting Remaining Columns of Matrix up to the 2nd Column#\n",
    "        for m in range(2, states):\n",
    "            start_temp = states - m\n",
    "            if abs(TTC_mat.iloc[[i], start_temp:states].sum(axis=1)-1).values<0.000000001:\n",
    "                PIT_mat.iloc[[i], start_temp] = 1-PIT_mat.iloc[[i], start_temp+1:states].sum(axis=1)\n",
    "            else:\n",
    "                PIT_mat.iloc[[i], start_temp] = \\\n",
    "                norm.cdf(norm.ppf(TTC_mat.iloc[[i], start_temp:states].sum(axis=1)) - shift_table[\"fcst\"][quarter]) \\\n",
    "                - norm.cdf(norm.ppf(TTC_mat.iloc[[i], start_temp+1:states].sum(axis=1)) - shift_table[\"fcst\"][quarter])\n",
    "\n",
    "        #First Column of Matrix Defined to Ensure Summation of Row to 1#\n",
    "        PIT_mat.iloc[[i], 0] = 1 - PIT_mat.iloc[[i], 1:states].sum(axis=1)\n",
    "\n",
    "    return PIT_mat\n",
    "\n",
    "#Call Function each segment and Store PIT Matrices in Lists#\n",
    "for s in range(0, len(segment)):\n",
    "    PIT_mat_fcst_list = {}\n",
    "    for h in range(0, len(PD_Forecast_Qtrs[\"period\"])):\n",
    "        if segment[s] in [\"Fin_US\", \"Fin_NUS\", \"Oil_US\", \"Oil_NUS\", \"Cyc_NUS\", \"NCy_NUS\", \"Sov\"]:      \n",
    "            PIT_mat_fcst_list[h] = PIT_matrix(TTC_mat = rel_mat()[s], shift_table1 = deepcopy(Shiftlist[segment[s]]), \\\n",
    "                                              shift_table2 = deepcopy(Shiftlist[segment[s]]), cut=21, quarter=h)\n",
    "        elif segment[s] == \"Cyc_US_2clst\":\n",
    "            PIT_mat_fcst_list[h] = PIT_matrix(TTC_mat = rel_mat()[s], shift_table1 = deepcopy(Shiftlist[\"Cyc_US1\"]), \\\n",
    "                                              shift_table2 = deepcopy(Shiftlist[\"Cyc_US2\"]), cut=18, quarter=h)\n",
    "        else:\n",
    "            PIT_mat_fcst_list[h] = PIT_matrix(TTC_mat = rel_mat()[s], shift_table1 = deepcopy(Shiftlist[\"NCy_US1\"]), \\\n",
    "                                              shift_table2 = deepcopy(Shiftlist[\"NCy_US2\"]), cut=18, quarter=h)\n",
    "        PIT_mat_fcst_AllSeg[h][s*states:(s+1)*states,:] = PIT_mat_fcst_list[h]\n",
    "    PIT_mat_fcst[s] = PIT_mat_fcst_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Store Marginal PD from PIT Matrices in One Table and Power Cumulative Matrix till Maximum Horizon --#\n",
    "\n",
    "PIT_pd_fcst_AllSeg = np.zeros((states*len(segment), horizon), dtype=float)\n",
    "for s in range(0, len(segment)):\n",
    "    #Cumulative Transition Matrix Till Period within reasonable and supportable period and Storing Marginal PDs#\n",
    "    PIT_pd_fcst = np.zeros((states, horizon), dtype=float)\n",
    "    PIT_Cumulative_fcst = PIT_mat_fcst[s][0].values\n",
    "    PIT_pd_fcst[:, 0] = PIT_Cumulative_fcst[:,states-1]\n",
    "    \n",
    "    for h in range(1, rs_len):\n",
    "        mat_cum_temp_prev = PIT_Cumulative_fcst.copy()\n",
    "        PIT_Cumulative_fcst = np.dot(PIT_Cumulative_fcst, PIT_mat_fcst[s][h])\n",
    "        PIT_pd_fcst[:, h] = PIT_Cumulative_fcst[:, states-1] - mat_cum_temp_prev[:,states-1]\n",
    "        \n",
    "    #Use Cumulative TM and Multiply it Further to Obtain Marginal PDs in Future Horizons  \n",
    "    def Marg_PD(cum_mat, last_mat, margPD_table):\n",
    "        mat_cum_temp = cum_mat.copy()\n",
    "        for h in range(rs_len, horizon):\n",
    "            mat_cum_temp_prev = deepcopy(mat_cum_temp)\n",
    "            mat_cum_temp = np.dot(mat_cum_temp, last_mat)\n",
    "            margPD_table[:, h] = mat_cum_temp[:, states-1] - mat_cum_temp_prev[:, states-1]\n",
    "        return margPD_table\n",
    "    \n",
    "    # Two options for the transition matrix used during the mean reversion period\n",
    "    # Option1: Use TTC matrix\n",
    "    # Option2: Use last PIT matrix\n",
    "    if reversion == 1:\n",
    "        reversion_mat = rel_mat()[s]\n",
    "    else:\n",
    "        reversion_mat = PIT_mat_fcst[s][rs_len-1]\n",
    "    \n",
    "    PIT_pd_fcst_f = Marg_PD(cum_mat = deepcopy(PIT_Cumulative_fcst), last_mat = deepcopy(reversion_mat), margPD_table = deepcopy(PIT_pd_fcst))\n",
    "    PIT_pd_fcst_AllSeg[s*states:(s+1)*states, :] = PIT_pd_fcst_f\n",
    "\n",
    "Marginal_PD = deepcopy(PIT_pd_fcst_AllSeg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate provisions\n",
    "\n",
    "# Select portfolio\n",
    "if portfolio == 1:\n",
    "    Data_temp1 = account_data[account_data.Product == \"C&I\"]\n",
    "elif portfolio == 2:\n",
    "    Data_temp1 = account_data[account_data.Product == \"CRE\"]\n",
    "else:\n",
    "    Data_temp1 = deepcopy(account_data)\n",
    "\n",
    "#--Define Columns Necessary for CECL Calculation --#\n",
    "#CECL: Expected Maturity#\n",
    "Data_temp1[\"CECL_RemMat\"] =  Data_temp1[\"RemMat\"]\n",
    "#CECL: Exposure#\n",
    "Data_temp1[\"Exp\"] = Data_temp1[\"EAD\"]\n",
    "\n",
    "#--Initial Number of Columns + 1--#\n",
    "col_initial = Data_temp1.shape[1] + 1\n",
    "\n",
    "#--Populate with Empty CECL Coloumns till Maximum Horizon --#\n",
    "for i in range(1,horizon):\n",
    "    Data_temp1[\"CECL_ECL_\"+str(i)] = 0\n",
    "\n",
    "\n",
    "#--a) Create Maginal PD until Maximum Horizon --#\n",
    "Data_MPD = deepcopy(Data_temp1)\n",
    "Data_MPD[\"obs\"] = Data_MPD.index+1\n",
    "Data_MPD = Data_MPD[[\"Rating\", \"obs\", \"Segment\"]]\n",
    "\n",
    "MPD = pd.DataFrame(Marginal_PD)\n",
    "for i in range(0, horizon):\n",
    "    MPD.rename(columns={i:\"MPD_\"+str(i+1)}, inplace=True)\n",
    "\n",
    "MPD[\"Rating\"] = np.tile(np.arange(1,states+1) , len(segment))\n",
    "MPD[\"Segment\"] = np.repeat(segment, states)\n",
    "\n",
    "Data_MPD = pd.merge(Data_MPD, MPD, how=\"left\", on=[\"Rating\", \"Segment\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--b) Create Prepayment Adjusted Marginal PD till Maximum Horizon --#\n",
    "Data_AdjMPD = deepcopy(Data_temp1)\n",
    "Data_AdjMPD[\"obs\"] = Data_AdjMPD.index+1\n",
    "Data_AdjMPD = Data_AdjMPD[[\"Rating\", \"obs\", \"Prepayment\", \"CECL_RemMat\", \"Segment\", \"Fee_Ind\", \"FAS114_ind\"]]\n",
    "\n",
    "#--Set prepayment based on prepayment rate from data or user specified prepayment rate--#\n",
    "if PP_option == 1:\n",
    "    Data_AdjMPD[\"pp\"] = PP_val\n",
    "else:\n",
    "    Data_AdjMPD[\"pp\"] = Data_AdjMPD[\"Prepayment\"]\n",
    "    \n",
    "for i in range(0, horizon):\n",
    "    Data_AdjMPD[\"adj_mpd_\"+str(i+1)] = 0\n",
    "\n",
    "cum_pd1_prev = Data_MPD[\"MPD_1\"]\n",
    "cond_pp_prev = Data_AdjMPD[\"pp\"]\n",
    "Data_AdjMPD[\"adj_mpd_1\"] = Data_MPD[\"MPD_1\"]\n",
    "cum_pd2_prev = Data_MPD[\"MPD_1\"]\n",
    "cum_pp_prev  = Data_AdjMPD[\"pp\"]\n",
    "sur_prev     = np.repeat(1, len(cond_pp_prev)) - cum_pd2_prev - cum_pp_prev\n",
    "\n",
    "for i in range(1, horizon):\n",
    "    cum_pd1_curr = cum_pd1_prev + Data_MPD[\"MPD_\"+str(i+1)] # current period cum PD based on unadjusted PD\n",
    "    cond_pd_curr = Data_MPD[\"MPD_\"+str(i+1)] / (1 - cum_pd1_prev) # current period conditional PD\n",
    "    cond_pp_curr = Data_AdjMPD[\"pp\"] # current period conditional prepayment rate\n",
    "    Data_AdjMPD[\"adj_mpd_\"+str(i+1)] = cond_pd_curr * sur_prev # current period unconditional PD adjusted for prepay and survive\n",
    "    adj_mpp_curr = cond_pp_curr * sur_prev # current period unconditional prepayment rate adjusted for default and survive\n",
    "    cum_pd2_curr = cum_pd2_prev + Data_AdjMPD[\"adj_mpd_\"+str(i+1)] # current period cum PD based on adjusted unconditional PD\n",
    "    cum_pp_curr  = cum_pp_prev + adj_mpp_curr # current period cumulative prepayment rate based on adjusted unconditional prepayment rate\n",
    "    sur_curr     = 1 - cum_pd2_curr - cum_pp_curr # current period surviorship\n",
    "    # Assign current period values as perviou period values in the next period calculation\n",
    "    cum_pd1_prev = deepcopy(cum_pd1_curr)\n",
    "    sur_prev     = deepcopy(sur_curr)\n",
    "    cum_pd2_prev = deepcopy(cum_pd2_curr)\n",
    "    cum_pp_prev  = deepcopy(cum_pp_curr)\n",
    "\n",
    "#For certain outstanding (deferred fees, uneanred discount, etc), use marginal PD without prepayment impact\n",
    "for i in range(1, horizon+1):\n",
    "    Data_AdjMPD.loc[Data_AdjMPD.Fee_Ind==1, \"adj_mpd_\"+str(i)] = Data_MPD.loc[Data_AdjMPD.Fee_Ind==1, \"MPD_\"+str(i)]\n",
    "    \n",
    "#Set marginal PD of the impaired loans (FAS 114) to 1 in the first quarter and to 0 beyond the first quarter #\n",
    "Data_AdjMPD.loc[Data_AdjMPD.FAS114_ind==1, \"adj_mpd_1\"] = 1\n",
    "for i in range(2, horizon+1):\n",
    "    Data_AdjMPD.loc[Data_AdjMPD.FAS114_ind==1, \"adj_mpd_\"+str(i)] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--c) Create LGD till Maximum Horizon --#\n",
    "\n",
    "Data_LGD = deepcopy(Data_temp1)\n",
    "Data_LGD[\"obs\"] = Data_LGD.index+1\n",
    "Data_LGD = Data_LGD[[\"Rating\", \"obs\", \"LGD\", \"CECL_RemMat\", \"Segment\"]]\n",
    "\n",
    "if LGD_option == 1:\n",
    "    for i in range(1, rs_len+1):\n",
    "        Data_LGD[\"lgd_\"+str(i)] = LGD_val\n",
    "else:\n",
    "    Data_LGD[\"FJ_K\"] = (norm.ppf(Data_AdjMPD[\"adj_mpd_1\"]) - norm.ppf(Data_AdjMPD[\"adj_mpd_1\"]*Data_LGD[\"LGD\"]))/(1 - 0.24)**0.5\n",
    "    for i in range(1, rs_len+1):\n",
    "        Data_LGD[\"lgd_\"+str(i)] = norm.cdf(norm.ppf(Data_AdjMPD[\"adj_mpd_\"+str(i)]) - Data_LGD[\"FJ_K\"])/Data_AdjMPD[\"adj_mpd_\"+str(i)]\n",
    "        \n",
    "for i in range(rs_len+1, horizon+1):\n",
    "    Data_LGD[\"lgd_\"+str(i)] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--d) Create EAD till Maximum Horizon --#\n",
    "Data_EAD = deepcopy(Data_temp1)\n",
    "Data_EAD[\"obs\"] = Data_EAD.index+1\n",
    "Data_EAD = Data_EAD[[\"Rating\", \"obs\", \"Exp\", \"CECL_RemMat\", \"Segment\", \"Amort_Type\", \"EIR\"]]\n",
    "\n",
    "for i in range(0, horizon):\n",
    "    Data_EAD[\"ead_\"+str(i+1)] = 0\n",
    "\n",
    "#--Set EAD based on Amortization Type--#\n",
    "cond1 = (Data_EAD.Amort_Type==\"IO\") | (Data_EAD.Amort_Type==\"Irregular\") | ((Data_EAD.Amort_Type==\"Level\") & (Data_EAD.EIR==0))\n",
    "cond2 = Data_EAD.Amort_Type==\"StraightLine\"\n",
    "cond3 = (Data_EAD.Amort_Type==\"Level\") & (Data_EAD.EIR>0)\n",
    "for i in range(1, horizon+1):\n",
    "    Data_EAD.loc[cond1, \"ead_\"+str(i)] = Data_EAD.loc[cond1, \"Exp\"]\n",
    "    Data_EAD.loc[cond2, \"ead_\"+str(i)] = Data_EAD.loc[cond2, \"Exp\"]*(1 - ((i-1)/Data_EAD[\"CECL_RemMat\"]))\n",
    "    Data_EAD.loc[cond3, \"ead_\"+str(i)] = Data_EAD.loc[cond3, \"Exp\"]* \\\n",
    "    ((1+Data_EAD.loc[cond3, \"EIR\"]/4)**Data_EAD[\"CECL_RemMat\"] - (1+Data_EAD.loc[cond3, \"EIR\"]/4)**(i-1)) / ((1+Data_EAD.loc[cond3, \"EIR\"]/4)**Data_EAD[\"CECL_RemMat\"] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--e) Calculate ECL till Maximum Horizon --#\n",
    "for i in range(1, horizon+1):\n",
    "    cond1 = Data_temp1.CECL_RemMat < i-1\n",
    "    cond2 = (Data_temp1.CECL_RemMat >= i-1) & (Data_temp1.CECL_RemMat < i)\n",
    "    cond3 = Data_temp1.CECL_RemMat >= i\n",
    "    \n",
    "    Data_temp1.loc[cond1, \"CECL_ECL_\"+str(i)] = 0\n",
    "    Data_temp1.loc[cond2, \"CECL_ECL_\"+str(i)] = Data_AdjMPD.loc[cond2, \"adj_mpd_\"+str(i)] \\\n",
    "    * Data_LGD.loc[cond2, \"lgd_\"+str(i)] * Data_EAD.loc[cond2, \"ead_\"+str(i)] * (Data_temp1.loc[cond2, \"CECL_RemMat\"] - (i-1))\n",
    "    Data_temp1.loc[cond3, \"CECL_ECL_\"+str(i)] = Data_AdjMPD.loc[cond3, \"adj_mpd_\"+str(i)] \\\n",
    "    * Data_LGD.loc[cond3, \"lgd_\"+str(i)] * Data_EAD.loc[cond3, \"ead_\"+str(i)]\n",
    "\n",
    "col_final = Data_temp1.shape[1]\n",
    "Data_temp1[\"ECL_Total\"] = Data_temp1.iloc[:,col_initial-1:col_final].sum(axis=1)\n",
    "\n",
    "Data_temp1.to_csv(\"ECL_python.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "new_index           \n",
      "Yr_1       13.739056\n",
      "Yr_2        4.890973\n",
      "Yr_3        1.695609\n",
      "Yr_4        1.174802\n",
      "Yr_5        0.457019\n",
      "Yr_6        0.000000\n",
      "Total      21.957459\n",
      "Index(['Yr_1', 'Yr_2', 'Yr_3', 'Yr_4', 'Yr_5', 'Yr_6', 'Total'], dtype='object', name='new_index')\n"
     ]
    }
   ],
   "source": [
    "ECL_qtr = Data_temp1.iloc[:,col_initial-1:col_final].sum(axis=0)\n",
    "yr = math.ceil(horizon/4)\n",
    "ECL_yr = np.zeros(yr+1)\n",
    "for i in range(0, yr):\n",
    "    ECL_yr[i] = ECL_qtr[i*4:(i+1)*4].sum()/1000000\n",
    "ECL_yr[yr] = ECL_yr[0:yr].sum()\n",
    "\n",
    "ECL_plot = pd.DataFrame(ECL_yr)\n",
    "new_index = []\n",
    "for i in range(1, yr+1):\n",
    "    new_index.append('Yr_'+str(i))\n",
    "new_index.append('Total') \n",
    "ECL_plot['new_index'] = new_index\n",
    "ECL_plot.set_index('new_index', inplace=True)\n",
    "print(ECL_plot)\n",
    "\n",
    "print(ECL_plot.index)\n",
    "\n",
    "trace = go.Bar(\n",
    "    x = ECL_plot.index, \n",
    "    y = ECL_plot[ECL_plot.columns[0]],\n",
    "    text = [round(x, 2) for x in ECL_plot[ECL_plot.columns[0]].tolist()],\n",
    "    textposition='auto',\n",
    "    marker=dict(\n",
    "        color=['rgba(0, 157, 255, 1)', 'rgba(0, 157, 255, 1)',\n",
    "               'rgba(0, 157, 255, 1)', 'rgba(0, 157, 255, 1)',\n",
    "               'rgba(0, 157, 255, 1)', 'rgba(0, 157, 255, 1)',\n",
    "               'rgba(255, 234, 5, 1)']),\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    title = 'Annual ECL in $million',\n",
    "    yaxis = dict(\n",
    "    title = 'ECL')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~tjt191/0 or inside your plot.ly account where it is named 'basic-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tjt191/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "plotly.__version__\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "\n",
    "py.iplot(fig, filename='basic-bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CECL_ECL_1  CECL_ECL_2  CECL_ECL_3  CECL_ECL_4  CECL_ECL_5  CECL_ECL_6  \\\n",
      "0    0.270722    2.036805    5.213668    9.668172    5.712795    4.419953   \n",
      "1    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "2    0.013048    0.276414    1.125123    2.704233    1.698455    1.324510   \n",
      "3    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "4    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "\n",
      "   CECL_ECL_7  CECL_ECL_8  CECL_ECL_9  CECL_ECL_10     ...       CECL_ECL_12  \\\n",
      "0    3.486259    2.552142    2.287523     2.033448     ...          1.898726   \n",
      "1   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "2    1.055007    0.762614    0.699102     0.633923     ...          0.635603   \n",
      "3   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "4   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "\n",
      "   CECL_ECL_13  CECL_ECL_14  CECL_ECL_15  CECL_ECL_16  CECL_ECL_17  \\\n",
      "0     1.821978     2.143842     1.927927     1.685093     1.413543   \n",
      "1    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "2     0.632321     0.725321     0.668383     0.597820     0.512521   \n",
      "3    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "4    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "\n",
      "   CECL_ECL_18  CECL_ECL_19  CECL_ECL_20  CECL_ECL_21  \n",
      "0     1.111350     0.776468     0.406759          0.0  \n",
      "1     6.098432     4.266255     2.235299          0.0  \n",
      "2     0.411322     0.293014     0.156340          0.0  \n",
      "3     6.098432     4.266255     2.235299          0.0  \n",
      "4     6.098432     4.266255     2.235299          0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   CECL_ECL_1  CECL_ECL_2  CECL_ECL_3  CECL_ECL_4  CECL_ECL_5  CECL_ECL_6  \\\n",
      "0    0.270722    2.036805    5.213668    9.668172    5.712795    4.419953   \n",
      "1    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "2    0.013048    0.276414    1.125123    2.704233    1.698455    1.324510   \n",
      "3    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "4    0.099925    1.522705    5.238787   10.529699   15.260903   15.684776   \n",
      "\n",
      "   CECL_ECL_7  CECL_ECL_8  CECL_ECL_9  CECL_ECL_10     ...       CECL_ECL_12  \\\n",
      "0    3.486259    2.552142    2.287523     2.033448     ...          1.898726   \n",
      "1   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "2    1.055007    0.762614    0.699102     0.633923     ...          0.635603   \n",
      "3   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "4   16.377234   14.772135   14.724518    13.566936     ...         11.786244   \n",
      "\n",
      "   CECL_ECL_13  CECL_ECL_14  CECL_ECL_15  CECL_ECL_16  CECL_ECL_17  \\\n",
      "0     1.821978     2.143842     1.927927     1.685093     1.413543   \n",
      "1    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "2     0.632321     0.725321     0.668383     0.597820     0.512521   \n",
      "3    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "4    10.894694    11.564578    10.464232     9.190889     7.737843   \n",
      "\n",
      "   CECL_ECL_18  CECL_ECL_19  CECL_ECL_20  CECL_ECL_21  \n",
      "0     1.111350     0.776468     0.406759          0.0  \n",
      "1     6.098432     4.266255     2.235299          0.0  \n",
      "2     0.411322     0.293014     0.156340          0.0  \n",
      "3     6.098432     4.266255     2.235299          0.0  \n",
      "4     6.098432     4.266255     2.235299          0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Data_temp1.iloc[:,col_initial-1:col_final].head())\n",
    "print(Data_temp1[Data_temp1.columns[-(1+horizon):-1]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
